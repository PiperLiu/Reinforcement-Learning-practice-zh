# ä½ å¥½ï¼Œè¿™æ˜¯åˆ˜æ´ªä½³çš„å¼ºåŒ–å­¦ä¹ ç¬”è®°

*ç¬¬ä¸€æ¬¡ç³»ç»Ÿå­¦ä¹ å¼ºåŒ–å­¦ä¹ ï¼Œæœ¬ç¬”è®°è¯­è¨€ä¸ºä¸­æ–‡ã€‚*

****

### æˆ‘çš„ç¬”è®°åˆ†å¸ƒ
- ğŸ¥Š å…¥é—¨å­¦ä¹  / è¯»ä¹¦ç¬”è®° [GitHubé“¾æ¥ï¼šPiperLiu/Reinforcement-Learning-practice-zh](https://github.com/PiperLiu/Reinforcement-Learning-practice-zh)
- ğŸ’» é˜…è¯»è®ºæ–‡ / è§†é¢‘è¯¾ç¨‹çš„ç¬”è®° [GitHubé“¾æ¥ï¼šPiperLiu/introRL](https://github.com/PiperLiu/introRL)
- âœ¨ å¤§å°ç®—æ³• / ç»ƒæ‰‹æ“åœº [GitHubé“¾æ¥ï¼šPiperLiu/Approachable-Reinforcement-Learning](https://github.com/PiperLiu/Approachable-Reinforcement-Learning)

### æ­£åœ¨è¿›è¡Œçš„å­¦ä¹ å†…å®¹ä¸è®¡åˆ’ä¸­çš„å†…å®¹
- [X] å¼ºåŒ–å­¦ä¹ åœ£ç»çš„ç¬¬ä¸€éå­¦ä¹  [[details]](#å¯¹å¼ºåŒ–å­¦ä¹ åœ£ç»çš„ç¬¬ä¸€éå­¦ä¹ )
- [ ] Deep Reinforcement Learning çš„ç¬¬ä¸€éé˜…è¯» [[details]](#æ·±åº¦å¼ºåŒ–å­¦ä¹ ç¬¬ä¸€éé˜…è¯»)
- [ ] Approximate Dynamic Programming çš„ç¬¬ä¸€éé˜…è¯» [[details]](#è¿‘ä¼¼åŠ¨æ€è§„åˆ’çš„ç¬¬ä¸€éé˜…è¯»)

****

### å¯¹å¼ºåŒ–å­¦ä¹ åœ£ç»çš„ç¬¬ä¸€éå­¦ä¹ 

**è¾“å‡ºæ˜¯æœ€å¥½çš„å­¦ä¹ ï¼Œæˆ‘çš„å­¦ä¹ æ–¹æ³•å¦‚ä¸‹ï¼š**
- è¯»ä¹¦ï¼Œä¸ºäº†ä¿è¯è¿›åº¦ï¼Œæˆ‘é€‰æ‹©é˜…è¯»ä¸­æ–‡ç‰ˆä¹¦ç±[[1-2]](#å‚è€ƒèµ„æ–™)ï¼›
- ä¸€èˆ¬åœ°ï¼Œæ¯è¯»å®Œä¸€ç« ï¼Œæˆ‘ä¼šæŠŠå…¶çŸ¥è¯†ä½“ç³»ç”¨è‡ªå·±çš„è¯­è¨€æ¦‚æ‹¬ä¸‹æ¥ï¼Œè¿™ä¼šå¼•å‘æˆ‘çš„å¾ˆå¤šæ€è€ƒï¼šå®Œæ•´åœ°å°†å…¶è¡¨è¿°å‡ºæ¥ï¼Œä¼šå¼¥è¡¥æˆ‘è¯»ä¹¦æ—¶æ²¡æœ‰æ³¨æ„åˆ°çš„é—®é¢˜ï¼›
- ç»“åˆä»£ç çš„ç¬”è®°ä¸å¿ƒå¾—ï¼Œä»¥ `.ipynb` æ–‡ä»¶å½¢å¼å†™åœ¨äº†[./practice/](./practice/)ä¸­ï¼Œæ²¡æœ‰ä»£ç çš„ï¼Œä»¥ `.md` å½¢å¼å†™åœ¨äº†[./mathematics/](./mathematics/)ä¸­ï¼›
- æˆ‘ä¼šå‚è€ƒä»–äººçš„ç¬”è®°ä¸æ€è€ƒï¼Œå¯¹æˆ‘å¸®åŠ©å¾ˆå¤§çš„æœ‰ï¼š
- - [github.com/ShangtongZhangn ä½¿ç”¨pythonå¤ç°ä¹¦ä¸Šæ¡ˆä¾‹](https://github.com/ShangtongZhang/reinforcement-learning-an-introduction)ï¼›
- - [github.com/brynhayder å¯¹äºæœ¬ä¹¦çš„ç¬”è®°ï¼Œå¯¹ç»ƒä¹ é¢˜çš„è§£ç­”](https://github.com/brynhayder/reinforcement_learning_an_introduction)ã€‚

ç›®å‰å·²å®Œæˆï¼š

- [X] ç¬¬Iéƒ¨åˆ† è¡¨æ ¼å‹æ±‚è§£æ–¹æ³• [å­¦ä¹ æ€»ç»“ link](./mathematics/è¡¨æ ¼å‹æ–¹æ³•æ€»ç»“.md)
- [X] ç¬¬IIéƒ¨åˆ† è¡¨æ ¼å‹è¿‘ä¼¼æ±‚è§£æ–¹æ³•
- [X] ç¬¬IIIéƒ¨åˆ† è¡¨æ ¼å‹æ·±å…¥ç ”ç©¶

å­¦ä¹ ç¬”è®°ç›®å½•ï¼ˆæ‰€æœ‰çš„`.ipynb`é“¾æ¥å·²è½¬æ¢åˆ°`nbviewer.jupyter.org/github/`ï¼‰ï¼š

##### ç¬¬Iéƒ¨åˆ† è¡¨æ ¼å‹æ±‚è§£æ–¹æ³•

- æ‘‡è‡‚èµŒåšæœºï¼š
- - å®ä¾‹ä»£ç ï¼š[01-Stochastic-Multi-Armed-Bandit.ipynb](https://nbviewer.jupyter.org/github/PiperLiu/Reinforcement-Learning-practice-zh/blob/master/practice/01-Stochastic-Multi-Armed-Bandit.ipynb)
- - æ•°å­¦å…¬å¼çš„è®¨è®ºï¼š[æ¢¯åº¦èµŒåšæœºç®—æ³•ä¸­ï¼Œåå¥½å‡½æ•°æ›´æ–°ï¼šæ¢¯åº¦ä¸Šå‡å…¬å¼æ˜¯ç²¾ç¡®æ¢¯åº¦ä¸Šå‡çš„éšæœºè¿‘ä¼¼çš„è¯æ˜.md](./mathematics/æ¢¯åº¦èµŒåšæœºç®—æ³•ä¸­ï¼Œåå¥½å‡½æ•°æ›´æ–°ï¼šæ¢¯åº¦ä¸Šå‡å…¬å¼æ˜¯ç²¾ç¡®æ¢¯åº¦ä¸Šå‡çš„éšæœºè¿‘ä¼¼çš„è¯æ˜.md)
- é©¬å°”ç§‘å¤«é“¾ä¸è´å°”æ›¼æ–¹ç¨‹ï¼š
- - å®ä¾‹ï¼š[02-MDP-and-Bellman-Equation.ipynb](https://nbviewer.jupyter.org/github/PiperLiu/Reinforcement-Learning-practice-zh/blob/master/practice/02-MDP-and-Bellman-Equation.ipynb)
- åŠ¨æ€è§„åˆ’ï¼š
- - å®ä¾‹1ï¼š[./practice/03-01-Grid-World.ipynb](https://nbviewer.jupyter.org/github/PiperLiu/Reinforcement-Learning-practice-zh/blob/master/practice/03-01-Grid-World.ipynb)
- - å®ä¾‹2ï¼š[./practice/03-02-Policy-Iteration.ipynb](https://nbviewer.jupyter.org/github/PiperLiu/Reinforcement-Learning-practice-zh/blob/master/practice/03-02-Policy-Iteration.ipynb)
- - å®ä¾‹3ï¼š[./practice/03-03-Value-Iteration-and-Asynchronous-etc.ipynb](https://nbviewer.jupyter.org/github/PiperLiu/Reinforcement-Learning-practice-zh/blob/master/practice/03-03-Value-Iteration-and-Asynchronous-etc.ipynb)
- è’™ç‰¹å¡æ´›æ–¹æ³•ï¼š[./practice/04-Monte-Carlo-Methods.ipynb](https://nbviewer.jupyter.org/github/PiperLiu/Reinforcement-Learning-practice-zh/blob/master/practice/04-Monte-Carlo-Methods.ipynb)
- ï¼ˆå•æ­¥ï¼‰æ—¶åºå·®åˆ†å­¦ä¹ ï¼š
- - è¯„ä¼°ä»·å€¼éƒ¨åˆ†ï¼š[./practice/05-01-Temporal-Difference-Prediction.ipynb](https://nbviewer.jupyter.org/github/PiperLiu/Reinforcement-Learning-practice-zh/blob/master/practice/05-01-Temporal-Difference-Prediction.ipynb)
- - æ§åˆ¶éƒ¨åˆ†ï¼š[./practice/05-02-Temporal-Difference-Control.ipynb](https://nbviewer.jupyter.org/github/PiperLiu/Reinforcement-Learning-practice-zh/blob/master/practice/05-02-Temporal-Difference-Control.ipynb)
- n æ­¥è‡ªä¸¾æ³•ï¼š[./practice/06-N-Step-Bootstrapping.ipynb](https://nbviewer.jupyter.org/github/PiperLiu/Reinforcement-Learning-practice-zh/blob/master/practice/06-N-Step-Bootstrapping.ipynb)
- è¡¨æ ¼å‹æ–¹æ³•çš„è§„åˆ’ä¸å­¦ä¹ ï¼š
- - **ä¹¦å‰å…«ç« æ€»ç»“ï¼š**[./mathematics/è¡¨æ ¼å‹æ–¹æ³•æ€»ç»“.md](https://nbviewer.jupyter.org/github/PiperLiu/Reinforcement-Learning-practice-zh/blob/master/mathematics/è¡¨æ ¼å‹æ–¹æ³•æ€»ç»“.md)
- - Dyna-Q ä¸ ä¼˜å…ˆéå†å®ä¾‹ï¼š[./practice/07-01-Maze-Problem-with-DynaQ-and-Priority.ipynb](https://nbviewer.jupyter.org/github/PiperLiu/Reinforcement-Learning-practice-zh/blob/master/practice/07-01-Maze-Problem-with-DynaQ-and-Priority.ipynb)
- - æœŸæœ›ä¼°è®¡ä¸é‡‡ç”¨ä¼°è®¡ï¼š[./practice/07-02-Expectation-vs-Sample.ipynb](https://nbviewer.jupyter.org/github/PiperLiu/Reinforcement-Learning-practice-zh/blob/master/practice/07-02-Expectation-vs-Sample.ipynb)
- - è½¨è¿¹é‡‡æ ·ï¼š[./practice/07-03-Trajectory-Sampling.ipynb](https://nbviewer.jupyter.org/github/PiperLiu/Reinforcement-Learning-practice-zh/blob/master/practice/07-03-Trajectory-Sampling.ipynb)

##### ç¬¬IIéƒ¨åˆ† è¡¨æ ¼å‹è¿‘ä¼¼æ±‚è§£æ–¹æ³•

- ç¬¬9ç« ï¼šåŸºäºå‡½æ•°é€¼è¿‘çš„åŒè½¨ç­–ç•¥é¢„æµ‹ï¼š
- - å¿ƒå¾—ï¼š[ç¬¬9ç« ï¼šåŸºäºå‡½æ•°é€¼è¿‘çš„åŒè½¨ç­–ç•¥é¢„æµ‹.md](./mathematics/ç¬¬9ç« ï¼šåŸºäºå‡½æ•°é€¼è¿‘çš„åŒè½¨ç­–ç•¥é¢„æµ‹.md)
- - å®ä¾‹ï¼ˆéšæœºæ¸¸èµ°ä¸ç²—ç¼–ç å¤§å°ï¼‰ï¼š[./practice/On-policy-Prediction-with-Approximation.ipynb](https://nbviewer.jupyter.org/github/PiperLiu/Reinforcement-Learning-practice-zh/blob/master/practice/On-policy-Prediction-with-Approximation.ipynb)
- ç¬¬10ç« ï¼šåŸºäºå‡½æ•°é€¼è¿‘çš„åŒè½¨ç­–ç•¥æ§åˆ¶:
- - å¿ƒå¾—ï¼š[ç¬¬10ç« ï¼šåŸºäºå‡½æ•°é€¼è¿‘çš„åŒè½¨ç­–ç•¥æ§åˆ¶.md](./mathematics/ç¬¬10ç« ï¼šåŸºäºå‡½æ•°é€¼è¿‘çš„åŒè½¨ç­–ç•¥æ§åˆ¶.md)
- - å®ä¾‹ï¼ˆnæ­¥Sarsaæ§åˆ¶ä¸å¹³å‡æ”¶ç›Šå®ä¾‹ï¼‰ï¼š[./practice/Mountain-Car-Acess-Control.ipynb](https://nbviewer.jupyter.org/github/PiperLiu/Reinforcement-Learning-practice-zh/blob/master/practice/Mountain-Car-Acess-Control.ipynb)
- ç¬¬11ç« ï¼šåŸºäºå‡½æ•°é€¼è¿‘çš„ç¦»è½¨ç­–ç•¥æ–¹æ³•ï¼š
- - å¿ƒå¾—ï¼š[ç¬¬11ç« ï¼šåŸºäºå‡½æ•°é€¼è¿‘çš„ç¦»è½¨ç­–ç•¥æ–¹æ³•.md](./mathematics/ç¬¬11ç« ï¼šåŸºäºå‡½æ•°é€¼è¿‘çš„ç¦»è½¨ç­–ç•¥æ–¹æ³•.md)
- - å®ä¾‹ï¼š[./practice/Counterexample.ipynb](https://nbviewer.jupyter.org/github/PiperLiu/Reinforcement-Learning-practice-zh/blob/master/practice/Counterexample.ipynb)
- ç¬¬12ç« ï¼šèµ„æ ¼è¿¹ï¼š
- - å¿ƒå¾—ï¼š[ç¬¬12ç« ï¼šèµ„æ ¼è¿¹.md](./mathematics/ç¬¬12ç« ï¼šèµ„æ ¼è¿¹.md)
- - å®ä¾‹:[./practice/Random-Walk-Mountain-Car.ipynb](https://nbviewer.jupyter.org/github/PiperLiu/Reinforcement-Learning-practice-zh/blob/master/practice/Random-Walk-Mountain-Car.ipynb)
- ç¬¬13ç« ï¼šç­–ç•¥æ¢¯åº¦æ–¹æ³•
- - å¿ƒå¾—ï¼š[ç¬¬13ç« ï¼šç­–ç•¥æ¢¯åº¦æ–¹æ³•.md](./mathematics/ç¬¬13ç« ï¼šç­–ç•¥æ¢¯åº¦æ–¹æ³•.md)
- - å®ä¾‹ï¼š[./practice/Short-Corridor.ipynb](https://nbviewer.jupyter.org/github/PiperLiu/Reinforcement-Learning-practice-zh/blob/master/practice/Short-Corridor.ipynb)

**** 

### æ·±åº¦å¼ºåŒ–å­¦ä¹ ç¬¬ä¸€éé˜…è¯»

å¬è¯´è¿™æœ¬ç»¼è¿°ä¸é”™ï¼š

[Li Y. Deep reinforcement learning: An overview[J]. arXiv preprint arXiv:1701.07274, 2017.](./resources/)

å¦‚æœæƒ³çœ‹çœ‹è®ºæ–‡ä¸ä»£ç ï¼Œå¯ä»¥è€ƒè™‘å…ˆçœ‹ï¼š

[https://github.com/ShangtongZhang/DeepRL](https://github.com/ShangtongZhang/DeepRL)

****

### è¿‘ä¼¼åŠ¨æ€è§„åˆ’çš„ç¬¬ä¸€éé˜…è¯»

åœ¨ç®¡ç†ä¸­ï¼Œå¼ºåŒ–å­¦ä¹ ï¼ˆè¿‘ä¼¼åŠ¨æ€è§„åˆ’ï¼‰æœ‰å“ªäº›åº”ç”¨ï¼Ÿè€å¸ˆç»™æˆ‘æ¨èäº†è¿™æœ¬ä¹¦ï¼š

[Powell W B. Approximate Dynamic Programming: Solving the curses of dimensionality[M]. John Wiley & Sons, 2007.](./resources/)

****

### å‚è€ƒèµ„æ–™

- [1] å¼ºåŒ–å­¦ä¹ ï¼ˆç¬¬2ç‰ˆï¼‰; [åŠ æ‹¿å¤§] Richard S. Sutton, [ç¾å›½] Andrew G. Barto; ä¿å‡¯ è¯‘.
- [2] åœ¨ä¸Šè¿°ä¹¦ç±å‡ºç‰ˆå‰ï¼Œæœ‰äººå·²ç»å¼€å§‹äº†ç¿»è¯‘å·¥ä½œï¼š[http://rl.qiwihui.com/](http://rl.qiwihui.com/).
- [3] è‹±æ–‡ç”µå­åŸç‰ˆåœ¨ï¼š[http://rl.qiwihui.com/zh_CN/latest/chapter1/introduction.html](http://rl.qiwihui.com/zh_CN/latest/chapter1/introduction.html)ï¼Œå·²ç»ä¸‹è½½åˆ°æœ¬ä»“åº“[./resources/Reinforcement Learning - An Introduction 2018.pdf](./resources/)
- [4] å¼ºåŒ–å­¦ä¹ è¯»ä¹¦ç¬”è®°ç³»åˆ—;å…¬ä¼—å·ï¼šè€è–›å¸¦ä½ å­¦Python(xue_python)

### æ›´å¤šå¹³å°

"è¾“å‡ºæ˜¯æœ€å¥½çš„å­¦ä¹ æ–¹å¼"â€”â€”æ¬¢è¿åœ¨å…¶ä»–å¹³å°æŸ¥çœ‹æˆ‘çš„å­¦ä¹ è¶³è¿¹ï¼

<a id="WeiXin"></a>
![](./doc/image/æ‰«ç _æœç´¢è”åˆä¼ æ’­æ ·å¼-å¾®ä¿¡æ ‡å‡†ç»¿ç‰ˆ.png)
